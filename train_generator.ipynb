{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train generator model (finetune gpt2) on google colab.  Run this as a TPU notebook.\n",
    "\n",
    "This is a lightweight wrapper around `train.py` that calls it from a notebook.\n",
    "\n",
    "You should run this after you've prepared a training corpus (`prep_generator_training_dataset.ipynb`).\n",
    "\n",
    "As in other notebooks, you should have a google drive folder with my fork of gpt2 (included as `gpt-2/`).  You should have downloaded the base 1558M model using `download_model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount drive, setup\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "%cd \"/content/drive/My Drive/gpt-2\"\n",
    "!pip3 install -r \"requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train.\n",
    "\n",
    "You must have ~6gb left on google drive for the checkpoint.  You should expect to get ~350 steps of training done before colab times out.  You can continue from the checkpoint repeatedly after that, possibly after waiting a little while to get TPU usage back for your account.\n",
    "\n",
    "Alas, I have not added anything to save optimizer state in the checkpoints, so the adam gradient accumulators will get reset every ~350 steps.\n",
    "\n",
    "Heuristics for how many steps to run:\n",
    "\n",
    "- you will see something like 'dataset has XX tokens'.\n",
    "  - divide XX by (1024 * 8).  this is how long an 'epoch' is, in steps\n",
    "  - i used to do roughly 1 epoch at learning rate ~1.4e-5.\n",
    "  - now i do roughly 2 to 2.5 epochs at learning rate ~6.5e-6, which is used below.\n",
    "  - so, i recommend doing roughly 2 to 2.5 epochs\n",
    "- alternately, look at the loss\n",
    "  - early on, avg loss should be in the 2.9-3.0 range.\n",
    "  - a \"good\" finetuned model should get below this to maybe ~2.5 or lower\n",
    "  - too low (eg <2) is bad\n",
    "- also, review the samples generated, and consider stopping if you like them at a given point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_YOUR_DATA = \"\"  # a directory you put your data in (text files or .npz)\n",
    "YOUR_MODEL_NAME = \"\"  # whatever you want to call your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!PYTHONPATH=/tensorflow-1.15.2/python3.6:/env/python:src/ python3 -u train.py \\\n",
    "        --model_name 1558M \\\n",
    "        --run_name {YOUR_MODEL_NAME} \\\n",
    "        --dataset {PATH_TO_YOUR_DATA} \\\n",
    "        --batch_size 8 \\\n",
    "        --learning_rate 0.0000065 \\\n",
    "        --eot_workaround \\\n",
    "        --rob_sampler \\\n",
    "        --save_every 20 \\\n",
    "        --sample_every 100 \\\n",
    "        --sample_num 8 \\\n",
    "        --sample_length 192 \\\n",
    "        --save_time 30000  \\\n",
    "        --max_to_keep 1 \\\n",
    "        --init_tpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after finishing training, create a directory under `models` with the model, and metadata needed to load the it and the corresponding encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir models/{YOUR_MODEL_NAME}\n",
    "\n",
    "!cp models/1558M/hparams.json models/{YOUR_MODEL_NAME}\n",
    "!cp models/1558M/vocab.bpe models/{YOUR_MODEL_NAME}\n",
    "!cp models/1558M/encoder.json models/{YOUR_MODEL_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
